{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ed78f8-4aa6-46c8-ab55-359727211a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **O bloco abaixo seta os endereços dos containeres das camadas de armazenamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73bdf99d-fb71-49c8-88aa-34eae52ee73f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cria um dicionário com os paths dos storage de cada camada a partir de um path padrão\n",
    "tiers = ['bronze-layer','silver-layer','gold-layer']\n",
    "adls_paths = {tier: f\"abfss://{tier}@medallionapistorage.dfs.core.windows.net/\" for tier in tiers}\n",
    "print(adls_paths)\n",
    "\n",
    "#Cria as variáveis contendo os paths de cada camada\n",
    "bronze_adls = adls_paths['bronze-layer']\n",
    "silver_adls = adls_paths['silver-layer']\n",
    "gold_adls = adls_paths['gold-layer']\n",
    "\n",
    "#Acessa os paths para verificar se estão corretos\n",
    "dbutils.fs.ls(bronze_adls)\n",
    "dbutils.fs.ls(silver_adls)\n",
    "dbutils.fs.ls(gold_adls)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70de4f36-213e-4a85-89a4-48f3c775f5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cria as variáveis contendo os paths de cada camada\n",
    "bronze_adls = adls_paths['bronze-layer']\n",
    "silver_adls = adls_paths['silver-layer']\n",
    "gold_adls = adls_paths['gold-layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1451a207-826d-43bb-8313-6a9003025c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Acessa os paths para verificar se estão corretos\n",
    "dbutils.fs.ls(bronze_adls)\n",
    "dbutils.fs.ls(silver_adls)\n",
    "dbutils.fs.ls(gold_adls)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0749cc54-ad3c-4311-bd06-4e637c24f3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Camada de extração dos dados da API\n",
    "Os dados são extraídos, considerando a paginação e o máximo de registros retornados por página e persistidos em seu formato original (.json) no storage **bronze**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b7c6145-a8b7-47d5-b93a-df53924c798d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "\n",
    "# Cria uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"Open Brewery\").getOrCreate()\n",
    "\n",
    "# Seta as variáveis iniciais para a requisição da API \n",
    "page=1 \n",
    "per_page=200\n",
    "full_response=[]\n",
    "\n",
    "# Faz a requisição GET para a API\n",
    "while True:\n",
    "    url = f\"https://api.openbrewerydb.org/v1/breweries?page={page}&{per_page}\"\n",
    "    print(f\"Buscando a página {page} da API\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        #Verifica se a resposta foi bem sucedida\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if not data:\n",
    "            print(\"Não foram retornados dados na resposta\")\n",
    "            break\n",
    "        else:\n",
    "            #Salva todas as respostas em uma lista \n",
    "            full_response.extend(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante a requisição: {e}\")\n",
    "        break\n",
    "    \n",
    "    page+=1\n",
    "\n",
    "#Indica o arquivo e salva os dados no formato json (de origem) no storage indicado\n",
    "file_path = f\"{bronze_adls}open_breweries_raw.json\" \n",
    "\n",
    "df = spark.createDataFrame(full_response)\n",
    "df.write.mode(\"overwrite\").json(file_path)\n",
    "\n",
    "\n",
    "print(f\"Os dados foram salvos no storage {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronzelayer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}